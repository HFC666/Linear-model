# 介绍

理解线性模型或早期文献中的混合线性模型的最好方法是首先回忆线性回归模型。线性回归模型可以表示为$y = X\beta+\epsilon$，其中$y$是观测向量，$X$是已知的协变量矩阵，$\beta$是未知的回归系数，并且$\epsilon$是误差向量。在这个模型中，回归系数被认为是固定的、未知的常数。但是，在某些情况下，假设这些系数中的一些是随机的也是有意义的。这些情况通常发生在观测结果相互关联的情况下。例如在医学研究中，随着时间的推移，观察通常是从同一个人身上收集的。我们可以合理地假设，来自同一个人的观察结果之间存在相关性，特别是在收集观察数据的时间相对较近的情况下。

要了解线性混合模型是如何对观测之间的相关性进行建模的，考虑上面的关于医学研究的例子。假设每个个体都与一个不可观测的随即效果相关联。令$y_{ij}$表示在时间$t_j$收集到的第$i$个个体的观测，$\alpha_i$表示表示第$i$个个体的随机效应。假设有$m$个个体。为了简化，我们假设所有个体的观测都在相同的时间点进行收集，即$t_1,\cdots,t_k$。则线性模型可以被表示为$y_{ij} = x^{\prime}_{ij}\beta + \alpha_i + \epsilon_{ij}, i = 1,\cdots,m,\quad j = 1,\cdots,k$，其中$x_{ij}$是已知的协变量向量，$\beta$是未知的回归系数，并且假设是独立同分布的，有零均值和方差$\sigma^2$；误差$\epsilon_{ij}$是独立同分布的，均值为零，方差为$\tau^2$，并且随机效应和误差是独立的。同一个个体的任何两个观测之间的关联为$\sigma^2/(\sigma^2+\tau^2)$，而来自不同个体的观察结果是不相关的。这个模型是所谓的纵向线性混合模型的特例。

一个广义线性模型可以被表示为：
$$
y = X\beta + Z\alpha + \epsilon
$$
其中$y$为观测向量，$X$是协变量矩阵，$\beta$是未知的回归系数矩阵，现在被称为固定效应，$Z$为一个已知的矩阵，$\alpha$被称为随机效应，$\epsilon$为误差向量。注意$\alpha$和$\epsilon$是不可观测的。与线性模型相比，很明显差异为$Z\alpha$，这个可以形成很多不同的形式，因此会产生种类丰富的模型。一个统计模型会有很多假设，对于上式我们的假设为随机效应和误差有零均值和有限方差。通常，协方差矩阵$G = \operatorname{Var}(\alpha)$和$R = \operatorname{Var}(\epsilon)$包含一些未知的离散度或方差分量。

